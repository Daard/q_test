{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9ffdd22-3b47-4bba-b378-1544effde020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c151c-33b9-4b6a-a1cb-607838ad3461",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22e57ee7-8d2f-409d-ab30-9fdc9fab878c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TODO: add instractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daafb8fd-3fec-4d38-a5f8-a73908fbd000",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfx                             1.14.0\n",
      "tfx-bsl                         1.14.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep tfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ca17f-0a9f-4b4c-bfe5-1ae35f670706",
   "metadata": {},
   "source": [
    "## 1. Counting Islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9eb1730-72c1-4092-a59f-0f8ab0ee4c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IslandsCounter:\n",
    "    def __call__(self, grid: List[List[int]]) -> int:\n",
    "        visited = set()\n",
    "        res = 0\n",
    "        N = len(grid)\n",
    "        M = len(grid[0])\n",
    "        for n in range(N):\n",
    "            for m in range(M):\n",
    "                if grid[n][m] == 0 or (n, m) in visited:\n",
    "                    continue\n",
    "                else:\n",
    "                    res += 1\n",
    "                    que = []\n",
    "                    visited.add((n, m))\n",
    "                    que.append((n, m))\n",
    "                    while que:\n",
    "                        a, b = que.pop()\n",
    "                        for i, j in [(a - 1, b), (a + 1, b ), (a, b + 1), (a, b - 1)]:\n",
    "                            if -1 < i < N and -1 < j < M and \\\n",
    "                                grid[i][j] == 1 and (i, j) not in visited:\n",
    "                                visited.add((i, j))\n",
    "                                que.append((i, j))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "263be833-a08f-4ca6-8228-c99c5efb8938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "tests = [[[0, 1, 0], \n",
    "          [0, 0, 0], \n",
    "          [0, 1, 1]], \n",
    "         [[0, 0, 0, 1], \n",
    "          [0, 0, 1, 0],\n",
    "          [0, 1, 0, 0]],\n",
    "         [[0, 0, 0, 1],\n",
    "          [0, 0, 1, 1],\n",
    "          [0, 1, 0, 1]]\n",
    "        ]\n",
    "\n",
    "counter = IslandsCounter()\n",
    "\n",
    "for grid in tests: \n",
    "    print(counter(grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf13f1c-34d7-4127-9b7c-e5ca1d36bfec",
   "metadata": {},
   "source": [
    "## 2. Regression on the tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a0a07a-b62b-4453-9cd9-b2d9f14fc325",
   "metadata": {},
   "source": [
    "#### 1. Run train script. The default parameter for --train_data is './data/train.csv'.  Results will be saved in the results.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ae6ec-ada1-4ad9-b393-5ecf9cbab58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python run_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7711f449-e8a8-4330-bfbd-2a396824c3eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. After run_train script is finished you may use new_model and new_tfx preprocessing layer to get fresh predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cca65af-945a-4dc8-820a-f857145ec09e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-19 07:36:00.397226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-19 07:36:02.256272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:06:00.0, compute capability: 8.6\n",
      "2024-07-19 07:36:02.256924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22204 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:82:00.0, compute capability: 8.6\n",
      "2024-07-19 07:36:02.257539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 1030 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:83:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "! python run_predict.py --data_path='./data_for_tfx/val.csv' --model_path='./new_model' --tfx_root='./new_tfx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f038d-9448-4bd5-a689-656de610de5f",
   "metadata": {},
   "source": [
    "#### 3. Or you can try cached_model and cached_tfx preprocessing layer which gave me the smallest mean_abs_percentage error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b5f892e-cc97-4c2a-ba83-68a982db8ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-19 07:41:30.349361: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-19 07:41:32.465261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:06:00.0, compute capability: 8.6\n",
      "2024-07-19 07:41:32.465912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22204 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:82:00.0, compute capability: 8.6\n",
      "2024-07-19 07:41:32.466487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 1030 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:83:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "! python run_predict.py --data_path='./data_for_tfx/val.csv' --model_path='./cached_model' --tfx_root='./cached_tfx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bf1d7-64e8-4505-9eaf-16c81828e82e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4. Results of hidden_test.csv is stored in the hidden_test_results.csv. I renamed results.csv for these inputs by hands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "459e38bd-9bee-4dfa-9306-c46a2ae277de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-19 08:01:57.102101: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-19 08:01:59.293365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:06:00.0, compute capability: 8.6\n",
      "2024-07-19 08:01:59.294023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22204 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:82:00.0, compute capability: 8.6\n",
      "2024-07-19 08:01:59.294594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 1030 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:83:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "! python run_predict.py --data_path='./data/hidden_test.csv' --model_path='./cached_model' --tfx_root='./cached_tfx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724cf469-af4e-487f-9b2f-f4d61ef206af",
   "metadata": {},
   "source": [
    "#### 5. Further researches\n",
    "\n",
    "I have finished the base model prototype. What could be done next? \n",
    "\n",
    "- Find optimal hyperparameters for the training process: learning rate, decay rate, epoch count, and gradient descent algorithms.\n",
    "- Neural architecture search: Make the net deeper and change batch__norm_block inner and output width. \n",
    "\n",
    "Both steps could be done via Katib (standalone or as a part of Kubeflow / Vertex). It is possible to configs the training job and experiment for this microservice. The main advantage of Katib is the ability to run several training jobs simultaneously and automate hyperparameters search via Bayesian optimization. \n",
    "\n",
    "- After we find the most optimal learning and net hyperparameters we can add Train, ModelEstimation, and Pusher components to the transform pipeline and create continuous building and training pipelines if it is possible to get a continuous amount of labeled data for the training process. We can run such pipelines locally, but the preferable way is to use Kubeflow pipelines, cause we can monitor data, and model shifts via artefacts visualization easily. \n",
    "\n",
    "- If we want an inference service for this model we can use KServe. It can help leverage GPU batch computation by creating a request queue sidecar service which will generate batches from atomic requests of users. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430aed63-e16d-4d07-bb4d-a33ef613cdb5",
   "metadata": {},
   "source": [
    "## 3. MNIST classifier. OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eb43d01-606c-49da-adaa-cae568b76a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the interface\n",
    "class DigitClassificationInterface(ABC):\n",
    "    \n",
    "    def __init__(self, shape:tuple):\n",
    "        self.shape = shape\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, image: np.ndarray) -> int:\n",
    "        pass\n",
    "    \n",
    "    def preprocess(self, image: np.ndarray) -> np.ndarray:\n",
    "        if type(image) != np.ndarray:\n",
    "            raise TypeError(\"image must be a numpy array\")\n",
    "            \n",
    "        prep_image = self._preprocess(image)\n",
    "        \n",
    "        if prep_image.shape != self.shape:\n",
    "            raise ValueError(f\"image shape must match {self.shape}, but got {prep_image.shape}\")\n",
    "            \n",
    "        return prep_image\n",
    "            \n",
    "    \n",
    "    @abstractmethod\n",
    "    def _preprocess(self, image: np.ndarray) -> int:\n",
    "        pass\n",
    "    \n",
    "\n",
    "# CNN Model implementation\n",
    "class CNNModel(DigitClassificationInterface):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__((28, 28, 1))\n",
    "    \n",
    "    def _preprocess(self, image: np.ndarray) -> np.ndarray:\n",
    "        return image\n",
    "    \n",
    "    def predict(self, image: np.ndarray) -> int:\n",
    "        # For demonstration, let's return a random number as placeholder\n",
    "        return np.random.randint(0, 10)\n",
    "\n",
    "# Random Forest Model\n",
    "class RFModel(DigitClassificationInterface):\n",
    "    def __init__(self):\n",
    "        # Initialize the random forest model\n",
    "        super().__init__((784,))\n",
    "    \n",
    "    def _preprocess(self, image:np.ndarray) -> np.ndarray:\n",
    "        return image.flatten()\n",
    "\n",
    "    def predict(self, image: np.ndarray) -> int:\n",
    "        return np.random.randint(0, 10)\n",
    "\n",
    "# Random Model\n",
    "class RandomModel(DigitClassificationInterface):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__((10, 10, 1))\n",
    "    \n",
    "    def _preprocess(self, image:np.ndarray) -> np.ndarray:\n",
    "        return image[9:19, 9:19]\n",
    "    \n",
    "    def predict(self, image: np.ndarray) -> int:\n",
    "        # Here we can ignore the input and return a random value\n",
    "        return np.random.randint(0, 10)\n",
    "\n",
    "# Digit Classifier\n",
    "class DigitClassifier:\n",
    "    def __init__(self, algorithm: str):\n",
    "        if algorithm == 'cnn':\n",
    "            self.model = CNNModel()\n",
    "        elif algorithm == 'rf':\n",
    "            self.model = RFModel()\n",
    "        elif algorithm == 'rand':\n",
    "            self.model = RandomModel()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported algorithm: {algorithm}\")\n",
    "            \n",
    "    def train(self, x:np.ndarray, labels:np.ndarray):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict(self, image: np.ndarray) -> int:\n",
    "        prepared_image = self.model.preprocess(image)\n",
    "        return self.model.predict(prepared_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c31f491-b80f-4390-b437-871ed439f7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Prediction: 9\n",
      "Random Forest Prediction: 8\n",
      "Random Model Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "# Create a random 28x28 image\n",
    "image = np.random.rand(28, 28, 1)\n",
    "\n",
    "# Create a DigitClassifier with a specific algorithm\n",
    "classifier = DigitClassifier(algorithm='cnn')\n",
    "prediction = classifier.predict(image)\n",
    "print(f\"CNN Prediction: {prediction}\")\n",
    "\n",
    "classifier = DigitClassifier(algorithm='rf')\n",
    "prediction = classifier.predict(image)\n",
    "print(f\"Random Forest Prediction: {prediction}\")\n",
    "\n",
    "classifier = DigitClassifier(algorithm='rand')\n",
    "prediction = classifier.predict(image)\n",
    "print(f\"Random Model Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9135b7a-89b0-4bf5-b590-629fd3a546ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
